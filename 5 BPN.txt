import numpy as np

def sigmoid(x):
    return 1/(1+np.exp(-x))
def sigmoid_der(x):
    return x*(1-x)

class NN:
    def __init__(self,inputs):
        self.inputs=inputs
        self.l=len(self.inputs)
        self.li=len(self.inputs[0])
        self.wi=np.random.random((self.li,self.l))
        self.wh=np.random.random((self.l,1))

    def test(self,inp):
        s1=sigmoid(np.dot(inp,self.wi))
        s2=sigmoid(np.dot(s1,self.wh))
        return s2

    def train(self,inputs,outputs,it):
        for i in range(it):
            l0= inputs
            l1=sigmoid(np.dot(l0,self.wi))
            l2=sigmoid(np.dot(l1,self.wh))
            l2_error=outputs-l2
            l2_delta=np.multiply(l2_error,sigmoid_der(l2))
            l1_error=np.dot(l2_delta,self.wh.T)
            l1_delta=np.multiply(l1_error,sigmoid_der(l1))
            self.wh+=np.dot(l1.T,l2_delta)
            self.wi+=np.dot(l0.T,l1_delta)
        print("weights of hidden layers",self.wh)
        print("weights of input layers",self.wi)

if __name__=="__main__":
        inputs=np.array([[0,0],[0,1],[1,0],[1,1]])
        outputs=np.array([[0],[1],[1],[0]])
        n=NN(inputs)
        n.train(inputs,outputs,10000)
        inp=[1,1]
        out=n.test(inp)
        print("output is",out)
        if(out>0.5):
            print("Predicted output for given input is high")
        else:
            print("predicted output for given input is low")


